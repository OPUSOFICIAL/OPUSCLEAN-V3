# üöÄ Modelos Groq Dispon√≠veis no OPUS

## ‚ö° O que √© Groq?

Groq √© uma plataforma de IA ultra-r√°pida que usa **LPU (Language Processing Unit)** - tecnologia pr√≥pria que √© **10x mais r√°pida que GPUs tradicionais**. Oferece acesso **100% gratuito** aos modelos Llama 3 da Meta.

---

## üìã Modelos Dispon√≠veis

### 1. **llama-3-groq-8b-tool-use** ‚≠ê RECOMENDADO PARA FUNCTION CALLING

**Uso ideal:** Function calling, ferramentas administrativas, chatbots com a√ß√µes

```json
{
  "model": "llama-3-groq-8b-tool-use",
  "messages": [...],
  "tools": [...],
  "temperature": 0.7,
  "max_tokens": 1500
}
```

**Vantagens:**
- ‚úÖ Especializado em function calling
- ‚úÖ Resposta ultra-r√°pida (~200 tokens/s)
- ‚úÖ Excelente para automa√ß√£o
- ‚úÖ Otimizado para chamadas de API e ferramentas
- ‚úÖ 8B par√¢metros (r√°pido e eficiente)

**Use quando:**
- Precisar chamar fun√ß√µes do sistema
- Automatizar tarefas administrativas
- Integrar com APIs e ferramentas
- Criar chatbots que executam a√ß√µes

---

### 2. **llama-3.3-70b-versatile** üéØ MODELO GERAL PODEROSO

**Uso ideal:** Conversa√ß√£o geral, an√°lise complexa, tarefas que exigem racioc√≠nio

```json
{
  "model": "llama-3.3-70b-versatile",
  "messages": [...],
  "temperature": 1,
  "max_tokens": 1024
}
```

**Vantagens:**
- ‚úÖ 70B par√¢metros (muito inteligente)
- ‚úÖ Vers√°til para qualquer tarefa
- ‚úÖ Melhor racioc√≠nio e compreens√£o
- ‚úÖ Excelente em portugu√™s
- ‚úÖ Ainda muito r√°pido (LPU)

**Use quando:**
- Precisar de respostas mais elaboradas
- An√°lise de dados complexos
- Conversa√ß√£o natural avan√ßada
- Tarefas que exigem racioc√≠nio profundo

---

### 3. **llama-3.1-70b-versatile**

**Uso ideal:** Alternativa est√°vel ao 3.3

```json
{
  "model": "llama-3.1-70b-versatile",
  "messages": [...],
  "temperature": 1,
  "max_tokens": 1024
}
```

**Caracter√≠sticas:**
- 70B par√¢metros
- Vers√£o anterior mais est√°vel
- √ìtimo desempenho geral

---

### 4. **llama-3.1-8b-instant**

**Uso ideal:** Respostas instant√¢neas, casos de uso simples

```json
{
  "model": "llama-3.1-8b-instant",
  "messages": [...],
  "temperature": 1,
  "max_tokens": 1024
}
```

**Vantagens:**
- ‚úÖ ULTRA R√ÅPIDO
- ‚úÖ Ideal para respostas curtas
- ‚úÖ Menor lat√™ncia poss√≠vel

**Use quando:**
- Precisar de respostas imediatas
- Tarefas simples de chat
- Alta frequ√™ncia de requisi√ß√µes

---

### 5. **mixtral-8x7b-32768**

**Uso ideal:** Contexto longo, documentos grandes

```json
{
  "model": "mixtral-8x7b-32768",
  "messages": [...],
  "temperature": 1,
  "max_tokens": 1024
}
```

**Vantagens:**
- ‚úÖ 32.768 tokens de contexto
- ‚úÖ Modelo Mixture-of-Experts
- ‚úÖ √ìtimo para documentos longos

---

### 6. **gemma2-9b-it**

**Uso ideal:** Modelo do Google Gemma

```json
{
  "model": "gemma2-9b-it",
  "messages": [...],
  "temperature": 1,
  "max_tokens": 1024
}
```

**Caracter√≠sticas:**
- Modelo do Google
- 9B par√¢metros
- Instruction-tuned

---

## üéØ Qual Modelo Escolher?

### Para OPUS (Sistema Administrativo):

**1¬™ Op√ß√£o: llama-3-groq-8b-tool-use** ‚≠ê
- Function calling nativo
- Responde: "Quantas O.S foram conclu√≠das?" com chamada de fun√ß√£o
- Ultra-r√°pido
- **MELHOR PARA: Chat AI do OPUS**

**2¬™ Op√ß√£o: llama-3.3-70b-versatile**
- Mais inteligente
- Melhor compreens√£o
- **MELHOR PARA: An√°lises complexas**

**3¬™ Op√ß√£o: llama-3.1-8b-instant**
- Respostas simples instant√¢neas
- **MELHOR PARA: FAQ e perguntas r√°pidas**

---

## üîß Configura√ß√£o no OPUS

### Passo 1: Obter API Key

1. Acesse: https://console.groq.com/keys
2. Fa√ßa login (gratuito)
3. Clique em **"Create API Key"**
4. Copie a chave (come√ßa com `gsk_...`)

### Passo 2: Configurar no Sistema

1. V√° em **Integra√ß√µes AI** (`/ai-integrations`)
2. Clique em **"Nova Integra√ß√£o AI"**
3. Preencha:
   - **Provedor:** Groq (Llama 3 Gr√°tis)
   - **Nome:** Opus Cloud (ou qualquer nome)
   - **API Key:** Cole sua chave `gsk_...`
   - **Modelo:** `llama-3-groq-8b-tool-use` (recomendado)
   - **Definir como padr√£o:** ‚úÖ Ativado

4. Clique em **"Testar"** para validar
5. Salve!

---

## üìä Compara√ß√£o R√°pida

| Modelo | Par√¢metros | Velocidade | Function Calling | Contexto | Uso Ideal |
|--------|-----------|-----------|-----------------|----------|-----------|
| **llama-3-groq-8b-tool-use** | 8B | ‚ö°‚ö°‚ö° Ultra | ‚úÖ Excelente | 8K | **Automa√ß√£o** |
| **llama-3.3-70b-versatile** | 70B | ‚ö°‚ö° Muito | ‚ö†Ô∏è B√°sico | 8K | **An√°lise** |
| **llama-3.1-8b-instant** | 8B | ‚ö°‚ö°‚ö° Ultra | ‚ùå N√£o | 8K | **FAQ** |
| **mixtral-8x7b-32768** | 8x7B | ‚ö°‚ö° Muito | ‚ö†Ô∏è B√°sico | 32K | **Docs** |

---

## üí° Exemplos de Uso no OPUS

### Function Calling (Recomendado)

**Usu√°rio:** "Quantas O.S foram conclu√≠das hoje?"

**LLM escolhe:** `llama-3-groq-8b-tool-use`
- Chama fun√ß√£o `queryWorkOrdersCount()`
- Retorna: "Foram conclu√≠das 15 O.S hoje!"

### Conversa√ß√£o Geral

**Usu√°rio:** "Explique o que √© SLA"

**LLM escolhe:** `llama-3.3-70b-versatile`
- Resposta completa e detalhada
- Melhor compreens√£o contextual

### Resposta Instant√¢nea

**Usu√°rio:** "Qual o hor√°rio agora?"

**LLM escolhe:** `llama-3.1-8b-instant`
- Resposta imediata
- Menor lat√™ncia

---

## üöÄ Vantagens do Groq sobre outros providers

| Feature | Groq | Google Gemini Free | OpenAI |
|---------|------|-------------------|--------|
| **Custo** | 100% Gr√°tis | 15 RPM limit | Pago |
| **Velocidade** | ‚ö°‚ö°‚ö° Ultra (LPU) | ‚ö° Normal | ‚ö°‚ö° R√°pido |
| **Function Calling** | ‚úÖ Nativo | ‚úÖ Sim | ‚úÖ Sim |
| **Rate Limit** | Generoso | üî¥ 15/min | üí∞ Pago |
| **Lat√™ncia** | <100ms | ~500ms | ~200ms |

---

## üìù Notas Importantes

- **Gr√°tis para sempre:** Groq √© 100% gratuito
- **Sem cart√£o de cr√©dito:** N√£o precisa cadastrar pagamento
- **Rate limits generosos:** Muito mais do que Google free tier
- **LPU Technology:** 10x mais r√°pido que GPUs tradicionais
- **Llama 3 oficial:** Modelos da Meta otimizados

---

## üéì Recursos Adicionais

- **Documenta√ß√£o oficial:** https://console.groq.com/docs
- **Playground:** https://console.groq.com/playground
- **Status:** https://status.groq.com/
- **Discord:** https://groq.com/discord

---

**√öltima atualiza√ß√£o:** Novembro 2024
